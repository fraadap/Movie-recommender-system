{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":6663,"sourceType":"datasetVersion","datasetId":3405},{"sourceId":7121520,"sourceType":"datasetVersion","datasetId":4107678}],"dockerImageVersionId":30805,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"pip install sentence-transformers tqdm\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\nfrom nltk.tokenize import word_tokenize\nfrom gensim.models import Doc2Vec\nfrom tqdm import tqdm\nfrom gensim.models.doc2vec import TaggedDocument\nfrom sklearn.metrics.pairwise import cosine_similarity\nimport numpy as np\nimport ast\n\nfrom sentence_transformers import SentenceTransformer","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-22T17:49:20.339695Z","iopub.execute_input":"2025-05-22T17:49:20.340086Z","iopub.status.idle":"2025-05-22T17:49:48.921472Z","shell.execute_reply.started":"2025-05-22T17:49:20.340046Z","shell.execute_reply":"2025-05-22T17:49:48.920779Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"import pandas as pd\nimport ast\n\n# Carica i dataset\ndf_movies = pd.read_csv('/kaggle/input/the-movies-dataset/movies_metadata.csv', low_memory=False)\ndf_keywords = pd.read_csv('/kaggle/input/the-movies-dataset/keywords.csv')\ndf_credits = pd.read_csv('/kaggle/input/the-movies-dataset/credits.csv')\n\n# Converte gli id in stringa per tutti i DataFrame\ndf_movies['id'] = df_movies['id'].astype(str)\ndf_keywords['id'] = df_keywords['id'].astype(str)\ndf_credits['id'] = df_credits['id'].astype(str)\n\n# Rimuove le righe con NaN nelle colonne 'original_title', 'title' e 'overview'\ndf_movies.dropna(subset=['original_title', 'title', 'overview'], inplace=True)\n\n# Funzione per estrarre i nomi dei generi\ndef estrai_generi(genres_str):\n    try:\n        genres = ast.literal_eval(genres_str)\n        return ', '.join([genre['name'] for genre in genres])\n    except (ValueError, SyntaxError, TypeError):\n        return ''\n\ndf_movies['genres_nomi'] = df_movies['genres'].apply(estrai_generi)\n\n# Funzione per estrarre il regista (director)\ndef estrai_regista(crew_str):\n    try:\n        crew = ast.literal_eval(crew_str)\n        for person in crew:\n            if person.get('job') == 'Director':\n                return person.get('name')\n    except:\n        return ''\n    return ''\n\n# Funzione per estrarre i primi 3 membri del cast\ndef estrai_cast(cast_str):\n    try:\n        cast = ast.literal_eval(cast_str)\n        return ', '.join([actor['name'] for actor in cast[:3]])  # primi 3 attori\n    except:\n        return ''\n\n# Estrai regista e cast\ndf_credits['regista'] = df_credits['crew'].apply(estrai_regista)\ndf_credits['cast_principale'] = df_credits['cast'].apply(estrai_cast)\n\n# Unisci tutti i DataFrame\ndf_completo = df_movies.merge(df_keywords[['id', 'keywords']], on='id', how='left') \\\n                       .merge(df_credits[['id', 'regista', 'cast_principale']], on='id', how='left')\n\n# Crea la colonna con le info combinate\ndf_completo['info_combinate'] = (\n    'Overview: ' + df_completo['overview'].fillna('') + '\\n' +\n    'Generi: ' + df_completo['genres_nomi'] + '\\n' +\n    'Lingua originale: ' + df_completo['original_language'].fillna('') + '\\n' +\n    'Titolo originale: ' + df_completo['original_title'].fillna('') + '\\n' +\n    'Regista: ' + df_completo['regista'].fillna('') + '\\n' +\n    'Cast principale: ' + df_completo['cast_principale'].fillna('')\n)\n\n# Aggiungi nota se il film è per adulti\ndf_completo['info_combinate'] = df_completo.apply(\n    lambda row: row['info_combinate'] + '\\nThe Film is for adult' if str(row['adult']).lower() == 'true' else row['info_combinate'],\n    axis=1\n)\n\n# Funzione per estrarre le parole chiave\ndef estrai_keywords(keywords_str):\n    try:\n        keywords = ast.literal_eval(keywords_str)\n        return ', '.join([k['name'] for k in keywords])\n    except:\n        return ''\n\ndf_completo['keywords_str'] = df_completo['keywords'].apply(estrai_keywords)\n\n# Aggiungi parole chiave (se presenti)\ndf_completo['info_combinate'] = df_completo.apply(\n    lambda row: row['info_combinate'] + '\\nKeywords: ' + row['keywords_str'] if row['keywords_str'] else row['info_combinate'],\n    axis=1\n)\n\n# Crea il nuovo DataFrame finale\ndf_nuovo = df_completo[['id', 'info_combinate']].copy()\n\n# Stampa il primo elemento\nprint(df_nuovo.iloc[0]['info_combinate'])\nprint(df_nuovo)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def ApplyBertEmbedding(Data, Feature, model_name='all-MiniLM-L6-v2', batch_size=8, output_file='bert_output.csv'):\n    # Carica il modello SBERT pre-addestrato\n    model = SentenceTransformer(model_name)\n\n    # Preprocess: rimuovi NaN e sostituisci newline\n    Data = Data.copy()\n    Data = Data[Data[Feature].notna()]\n    Data['Index'] = list(Data.index)\n    Data['CleanedText'] = Data[Feature].str.replace('\\n\\n', ' ', regex=False)\n\n    # Calcola gli embedding in batch\n    all_embeddings = []\n    for i in tqdm(range(0, len(Data), batch_size)):\n        batch_texts = Data['CleanedText'].iloc[i:i+batch_size].tolist()\n        batch_embeddings = model.encode(batch_texts, show_progress_bar=False)\n        all_embeddings.extend(batch_embeddings)\n\n    # Crea un DataFrame con gli embedding\n    embeddings_df = pd.DataFrame(all_embeddings)\n    embeddings_df['id'] = Data['id'].values\n\n    # Salva su file\n    embeddings_df.to_csv(output_file, index=False)\n\n    return embeddings_df, model\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-22T17:54:54.902444Z","iopub.execute_input":"2025-05-22T17:54:54.903136Z","iopub.status.idle":"2025-05-22T17:54:54.909562Z","shell.execute_reply.started":"2025-05-22T17:54:54.903101Z","shell.execute_reply":"2025-05-22T17:54:54.908598Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"result_df, model = ApplyBertEmbedding(df_nuovo, 'info_combinate', batch_size=8, output_file='doc2vec_output.csv')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"np.save('/kaggle/working/embeddings.npy', result_df.to_numpy())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-22T17:57:08.046419Z","iopub.execute_input":"2025-05-22T17:57:08.046799Z","iopub.status.idle":"2025-05-22T17:57:10.862164Z","shell.execute_reply.started":"2025-05-22T17:57:08.046755Z","shell.execute_reply":"2025-05-22T17:57:10.861179Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"plot = 'A adventure movies in a jungle'\n#overview = jumanji['overview'].values[0].replace(\"\\n\\n\", ' ')\noverview = plot.replace(\"\\n\\n\", ' ')\n\nembedding = model.encode(overview)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-22T17:58:00.742334Z","iopub.execute_input":"2025-05-22T17:58:00.742697Z","iopub.status.idle":"2025-05-22T17:58:00.784842Z","shell.execute_reply.started":"2025-05-22T17:58:00.742666Z","shell.execute_reply":"2025-05-22T17:58:00.783953Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"561a46b6ff6d4c0fbff32784deddcdb1"}},"metadata":{}}],"execution_count":8},{"cell_type":"code","source":"vectors_df = result_df.iloc[:, :-1].values  # I primi 300 sono i vettori, quindi prendi tutte le righe e le prime 300 colonne\n\n# Ottieni il vettore di embedding del nuovo testo\n# 'embedding' è il vettore del nuovo documento inferito\nembedding = embedding.reshape(1, -1)  # Assicurati che il vettore sia una matrice di dimensione (1, 300)\n\n# Calcola la similarità coseno tra l'embedding e tutti i vettori nel DataFrame\nsimilarities = cosine_similarity(embedding, vectors_df)\n\n# Ora, 'similarities' è un array che contiene le similarità coseno tra il nuovo vettore e tutti i vettori nel DataFrame\n# Ordina i risultati per somiglianza decrescente e prendi i primi 5\ntop_5_indices = np.argsort(similarities[0])[::-1][:5]  # Ordina in ordine decrescente\n\n# Estrai i titoli corrispondenti agli indici trovati\ntop_5_titles = result_df.iloc[top_5_indices, -1].values  # Assumiamo che la penultima colonna contenga i titoli\n\n# Stampa i titoli dei 5 documenti più simili\nprint(top_5_titles)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"for idx in top_5_titles:\n    plot = df_completo[df_completo['id'] == idx]['info_combinate'].iloc[0]\n    print(f\"{plot}\\n\")","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}